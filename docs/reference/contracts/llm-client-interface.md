# LlmClientInterface

L'interface `LlmClientInterface` est le connecteur universel de Synapse Core. C'est elle qui permet de dialoguer avec les diff√©rents fournisseurs d'IA (OpenAI, Gemini, Mistral, Ollama, etc.) en utilisant un langage commun.

## üõ† Pourquoi l'utiliser ?

*   **Ind√©pendance du fournisseur** : Changez de moteur d'IA en changeant une seule ligne de configuration sans toucher √† votre code m√©tier.
*   **Support du Streaming** : Permet de recevoir des r√©ponses en temps r√©el "mot par mot".
*   **Standardisation** : Transforme les r√©ponses disparates des API en objets `SynapseMessage` coh√©rents.

---

## üìã R√©sum√© du Contrat

| M√©thode | Entr√©e | Sortie | R√¥le |
| :--- | :--- | :--- | :--- |
| `supports(string $provider)` | Nom du provider | `bool` | D√©termine si ce client peut g√©rer la demande. |
| `generateResponse(...)` | Messages + Options | `SynapseMessage` | Appel synchrone classique. |
| `generateStream(...)` | Messages + Options | `iterable` | Appel asynchrone pour streaming. |
| `getCredentialFields()` | - | `array` | Liste les cl√©s API n√©cessaires (ex: `api_key`). |

---

## üöÄ Exemple : Un client factice pour vos tests

=== "FakeLlmClient.php"

    ```php
    namespace App\Synapse\Client;

    use ArnaudMoncondhuy\SynapseCore\Contract\LlmClientInterface;
    use ArnaudMoncondhuy\SynapseCore\Storage\Entity\SynapseMessage;
    use ArnaudMoncondhuy\SynapseCore\Shared\Enum\MessageRole;

    class FakeLlmClient implements LlmClientInterface
    {
        public function supports(string $provider): bool
        {
            return $provider === 'fake';
        }

        public function generateResponse(array $messages, array $options = []): SynapseMessage
        {
            $response = new SynapseMessage();
            $response->setRole(MessageRole::MODEL);
            $response->setContent("Ceci est une r√©ponse simul√©e.");
            
            return $response;
        }

        public function generateStream(array $messages, array $options = []): iterable
        {
            yield "Ceci ";
            yield "est ";
            yield "un ";
            yield "flux.";
        }

        public function getCredentialFields(): array
        {
            return ['api_key'];
        }
    }
    ```

---

## üí° Conseils d'impl√©mentation

> [!IMPORTANT]
> **Format OpenAI Canonical** : L'argument `$messages` re√ßu par ces m√©thodes est au format canonique OpenAI (`role` et `content`). Cela garantit une compatibilit√© maximale.

*   **Options LLM** : Le tableau `$options` contient les param√®tres techniques tels que `temperature`, `max_output_tokens` et les outils (`tools`). Veillez √† les traduire fid√®lement pour votre API cible.
*   **Credential Fields** : Les champs retourn√©s par `getCredentialFields` appara√Ætront automatiquement dans l'interface d'administration de Synapse Core.

---


