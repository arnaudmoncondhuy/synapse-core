# ChatService

Le `ChatService` est le point d'entr√©e principal de Synapse Core. C'est l'orchestrateur qui g√®re la communication avec le LLM, la gestion du contexte, l'appel des outils et le streaming.

## üõ† Pourquoi l'utiliser ?

*   **Simplicit√©** : Envoyez un message et recevez une r√©ponse IA avec une seule ligne de code.
*   **Orchestration automatique** : Il g√®re pour vous le cycle de vie des promps, les it√©rations d'outils et le stockage des messages.
*   **Performance** : Supporte nativement le streaming pour une exp√©rience utilisateur fluide.

---

## üìã M√©thodes principales

| M√©thode | Entr√©e | Sortie | R√¥le |
| :--- | :--- | :--- | :--- |
| `ask(string $message, array $options)` | Message brut | `string` | D√©clenche un √©change complet avec le LLM. |

---

## üöÄ Utilisation classique

Voici comment utiliser le service dans un contr√¥leur Symfony.

=== "ChatController.php"

    ```php
    namespace App\Controller;

    use ArnaudMoncondhuy\SynapseCore\Core\Chat\ChatService;
    use Symfony\Bundle\FrameworkBundle\Controller\AbstractController;
    use Symfony\Component\HttpFoundation\Response;

    class ChatController extends AbstractController
    {
        public function index(ChatService $chatService): Response
        {
            $response = $chatService->ask("Bonjour, peux-tu m'aider ?", [
                'model' => 'gemini-1.5-flash',
                'temperature' => 0.7,
                'stream' => false
            ]);

            return new Response($response);
        }
    }
    ```

---

## ‚öôÔ∏è Options disponibles

La m√©thode `ask()` accepte un tableau d'options pour personnaliser l'√©change :

*   **`model`** : Identifiant technique du mod√®le LLM √† utiliser.
*   **`temperature`** : (float) Entre 0.0 et 1.0 (cr√©ativit√©).
*   **`stream`** : (bool) Si vrai, le service √©mettra des √©v√©nements pour chaque token re√ßu.
*   **`max_output_tokens`** : Limite la longueur de la r√©ponse.
*   **`debug`** : (bool) Active le logging d√©taill√© de l'√©change.

---

## üí° Conseils d'utilisation

> [!TIP]
> **Streaming** : Pour utiliser le streaming, passez `stream: true` et √©coutez l'√©v√©nement `SynapseChunkReceivedEvent`. Cela permet d'afficher la r√©ponse au fur et √† mesure qu'elle arrive, comme sur ChatGPT.

---


