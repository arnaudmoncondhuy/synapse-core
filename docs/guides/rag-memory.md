# Mise en Å“uvre du RAG (MÃ©moire Vectorielle)

Le RAG (*Retrieval-Augmented Generation*) permet Ã  l'IA d'accÃ©der Ã  vos propres documents (PDF, Doc, Base de donnÃ©es) pour rÃ©pondre de maniÃ¨re prÃ©cise et sourcÃ©e, tout en s'affranchissant des limites de la fenÃªtre de contexte.

---

## ğŸš€ Ã‰tape 1 : Configuration du Vector Store

Synapse Core supporte plusieurs modes de stockage via l'option `vector_store.default`.

### Mode Doctrine / PostgreSQL (RecommandÃ©)
Si vous utilisez PostgreSQL avec l'extension `pgvector`, Synapse utilisera des requÃªtes natives ultra-performantes.

```yaml
# config/packages/synapse.yaml
synapse:
    vector_store:
        default: doctrine
```

> [!IMPORTANT]
> N'oubliez pas d'exÃ©cuter `php bin/console doctrine:schema:update --force` pour crÃ©er la table `synapse_vector_memory`.

---

## ğŸ§© Ã‰tape 2 : Configuration du Chunking

Avant d'Ãªtre mÃ©morisÃ©s, les documents doivent Ãªtre dÃ©coupÃ©s. Vous pouvez rÃ©gler ces paramÃ¨tres dans l'**Admin Synapse** (Onglet Embeddings) :

1.  **StratÃ©gie** : Choisissez `Recursive` pour un dÃ©coupage qui respecte les paragraphes.
2.  **Taille des segments** : 1000 caractÃ¨res est un bon compromis.
3.  **Overlap** : 200 caractÃ¨res permettent de garder le fil entre deux segments.

---

## ğŸ›  Ã‰tape 3 : Alimenter la mÃ©moire (RAG)

Pour ajouter des documents Ã  la mÃ©moire de l'IA, utilisez le `MemoryManager` (recommandÃ©) ou directement le `VectorStoreInterface` :

```php
use ArnaudMoncondhuy\SynapseCore\Core\Memory\MemoryManager;
use ArnaudMoncondhuy\SynapseCore\Shared\Enum\MemoryScope;

public function indexDocument(string $text, MemoryManager $memory, string $userId)
{
    $memory->remember(
        text: $text,
        scope: MemoryScope::USER,
        userId: $userId,
        sourceType: 'document'
    );
}
```

---

## ğŸ§  Comment Synapse utilise le RAG ?

Lors d'une conversation, Synapse Core :
1.  Vectorise la question de l'utilisateur.
2.  Recherche les **N** segments les plus proches dans le `VectorStore` (filtrÃ© par `user_id`).
3.  Injecte ces segments dans le prompt sous forme de "Contexte de rÃ©fÃ©rence".
4.  L'IA rÃ©pond en se basant sur ces documents.

> [!TIP]
> Vous pouvez surveiller les requÃªtes RAG et les scores de similaritÃ© en activant le `debug_mode` dans la configuration.

---

## ğŸ§¬ MÃ©moire SÃ©mantique Active (Human-in-the-loop)

En plus du RAG classique (documents prÃ©-indexÃ©s), Synapse Core dispose d'un systÃ¨me de **mÃ©moire conversationnelle** oÃ¹ le LLM peut proposer de retenir des informations importantes avec le consentement de l'utilisateur.

ğŸ‘‰ Voir le guide dÃ©diÃ© : [MÃ©moire SÃ©mantique](semantic-memory.md)
