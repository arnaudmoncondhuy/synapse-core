# Changelog

Toutes les modifications importantes de Synapse Core sont document√©es dans ce fichier.

Les modifications importantes sont class√©es par cat√©gorie :
- **Features** : Nouvelles fonctionnalit√©s
- **Fixes** : Corrections de bugs
- **Refactor** : Refactorisations de code
- **Security** : Am√©liorations de s√©curit√©
- **Docs** : Mises √† jour de documentation

---

## [Non class√©] ‚Äî D√©veloppement actuel

### Security

#### Durcissement Agnostique (Agnostic Security Shield)
- **Autorisation Agnostique** : Remplacement des r√¥les en dur (`#[IsGranted]`) par une v√©rification via `PermissionCheckerInterface` dans tous les contr√¥leurs (Admin & API).
- **Secure by Default** : Le bundle refuse d√©sormais tout acc√®s admin si aucun syst√®me de s√©curit√© n'est configur√© (correction de la posture trop permissive).
- **Protection CSRF** : Validation syst√©matique des jetons CSRF pour toutes les actions mutables (POST/PUT/DELETE) dans l'admin et l'API de chat.
- **Support AJAX/API** : Support des jetons via le header `X-CSRF-Token` pour une int√©gration fluide avec les frameworks frontend.
- **Permission Checker** : Ajout de la m√©thode `canCreateConversation()` pour prot√©ger le point d'entr√©e du chat.

### Features

#### üß† M√©moire S√©mantique "Human-in-the-loop"

Nouveau syst√®me de m√©moire conversationnelle avec consentement explicite :

- **`ProposeMemoryTool`** : Le LLM peut proposer de m√©moriser un fait important via un AI Tool d√©di√©. Il retourne un signal JSON (`__synapse_action: memory_proposal`) sans sauvegarder directement.
- **`MemoryManager`** : Service de haut niveau (`remember`, `recall`, `forget`, `listForUser`, `update`) avec vectorisation automatique via `EmbeddingService`.
- **`MemoryScope`** : Enum `USER` (souvenir permanent) / `CONVERSATION` (√©ph√©m√®re).
- **`MemoryApiController`** : Endpoints REST `/synapse/api/memory/{confirm,reject,list,delete}`.
- **Toast Frontend** : Notification non-bloquante dans le chat (‚úì/‚úï). Auto-dismiss apr√®s 30 secondes.
- **`MemoryContextSubscriber`** : Injection automatique des souvenirs pertinents (score ‚â• 0.7) dans le prompt avant chaque appel LLM.
- **Data Sealing** : Filtrage `user_id` impos√© au niveau SQL dans `DoctrineVectorStore` ‚Äî isolation totale garantie.
- **`SynapseVectorMemory` enrichie** : 5 nouvelles colonnes (`user_id`, `scope`, `conversation_id`, `content`, `source_type`).
- **Dashboard Admin** : KPI "Souvenirs m√©moris√©s" ajout√©.

#### Vectorisation dynamique du Vector Store

- **`VectorStoreRegistry`** : Registre centralis√© des impl√©mentations de stockage.
- **`DynamicVectorStore`** : R√©solveur dynamique du moteur de stockage (sans red√©marrage).
- **Interface Admin Embeddings** : S√©lection du Vector Store depuis l'interface.
- **Visualiseur de Chunking** : Aper√ßu interactif avec mise √† l'√©chelle adaptative (jusqu'√† 20k chars).

- **Refactorisation majeure** : ChatService utilise maintenant OpenAI Chat Completions comme format interne standard
- **Impact** : Bundle maintenant 100% LLM-agnostique (pr√™t pour Mistral, Claude, Ollama, etc.)
- **Changement de format** : Message syst√®me int√©gr√© comme premier √©l√©ment de `contents` array
  - **Avant** : `systemInstruction` (string) + `contents` (array) s√©par√©s
  - **Apr√®s** : Tous les messages dans `contents` avec `role: 'system'` en t√™te (format OpenAI)
- **Clients LLM** : Chacun devient un simple "traducteur"
  - GeminiClient : Extrait syst√®me de contents, convertit OpenAI‚ÜíGemini, traduit les cat√©gories de s√©curit√©
  - OvhAiClient : Passthrough pur (d√©j√† compatible OpenAI)
  - Nouveaux providers : Impl√©mentation simple en 2-3 heures (juste la couche de conversion)
- **ChatService** : Z√©ro logique sp√©cifique au provider (s√©curit√©, safety settings, etc. g√©r√©s par les clients)
- **Chunk format** : Changement de `blocked_category` ‚Üí `blocked_reason` (raison lisible)
- **S√©curit√© Gemini** : Toujours fonctionnelle, traduction d√©plac√©e du centre √† la p√©riph√©rie

**Pour les d√©veloppeurs cr√©ant des clients personnalis√©s** : Voir le [guide d'impl√©mentation](reference/implementation-guide.md)

#### Chiffrement des credentials des providers LLM
- Impl√©mentation du chiffrement XSalsa20-Poly1305 pour les credentials (API keys, service account JSON)
- Chiffrement automatique lors de la sauvegarde via l'interface admin
- D√©chiffrement transparent lors du chargement en m√©moire
- Support `encryption.enabled: true/false` dans la configuration
- Cl√©s sensibles encrypt√©es : `api_key`, `service_account_json`, `private_key`
- Format de stockage : `base64(nonce_24bytes + ciphertext)` en BDD
- Migration progressive : d√©tection automatique des credentials non chiffr√©s lors de la sauvegarde

#### Vidage des logs de debug
- Nouvelle fonctionnalit√© dans l'interface admin : vidage complet des logs de debug
- Contr√¥le d'acc√®s : accessible aux administrateurs uniquement
- Endpoint d√©di√© pour la gestion des logs

#### Support multi-providers
- Google Vertex AI (Gemini 2.5+, 2.0-pro, etc.)
- OVH AI Endpoints (OpenAI-compatible)
- Interface admin pour g√©rer les credentials et tester la connexion

#### Interface d'administration compl√®te
- Dashboard avec KPIs (conversations, utilisateurs, tokens, co√ªts)
- Analytics avec graphiques (usage par mod√®le, tendances temporelles)
- Gestion des presets LLM (cr√©ation, √©dition, test)
- Gestion des providers (credentials chiffr√©s)
- Catalogue des mod√®les disponibles
- Param√®tres globaux (r√©tention RGPD, langue, prompt syst√®me)
- Logs de debug complets (requ√™te/r√©ponse LLM, tokens, safety ratings)

#### Personas IA
- Support des personnalit√©s IA pr√©d√©finies
- Fichier JSON configurable (`personas_path`)
- Chaque persona : nom, emoji, prompt syst√®me custom

#### Context Caching (Gemini)
- Support du caching de contexte pour optimiser les co√ªts
- ~90% d'√©conomie sur les tokens de contexte r√©utilis√©s

#### Thinking Mode natif
- Support du raisonnement Chain-of-Thought (Gemini 2.5+)
- Configuration : `thinking.enabled`, `thinking.budget`

#### Token tracking
- Suivi de la consommation de tokens par mod√®le
- Calcul automatique des co√ªts bas√© sur la pricing
- Analytics : co√ªts par mod√®le, par utilisateur, par p√©riode

### Refactoring

#### Architecture domain-driven
- R√©organisation compl√®te du code source en domaines :
  - `Core/` : logique m√©tier, orchestration LLM
  - `Admin/` : contr√¥leurs et UI administration
  - `Storage/` : persistance Doctrine, entit√©s, repositories
  - `Security/` : chiffrement, permissions
  - `Contract/` : interfaces publiques (API du bundle)
  - `Shared/` : code r√©utilisable (enums, models, tools, utils)
  - `Infrastructure/` : DI, commandes CLI, ressources/views

#### Chargement des configurations mod√®les
- Priorisation : dossier `Infrastructure/config/models/` en premier, fallback sur `Core/`
- Permet une meilleure organisation des fichiers de configuration

#### Registration de DebugController
- Enregistrement explicite comme service Symfony
- Correction : √©tait manquant dans la configuration admin

### Security

#### Chiffrement des messages
- Messages de conversation chiffr√©s en BDD (XSalsa20-Poly1305)
- D√©chiffrement automatique lors de la lecture
- Transparent pour l'utilisateur/d√©veloppeur

#### Chiffrement des credentials
- Credentials des providers chiffr√©s (d√©crit ci-dessus)
- Migration progressive des credentials existants

#### Contr√¥le d'acc√®s
- Interface admin prot√©g√©e par r√¥le Symfony (`ROLE_ADMIN`)
- V√©rification des permissions √† chaque action

### Docs

#### Refonte compl√®te de la documentation
- README.md : rewritten avec 2 providers (Gemini + OVH), vraies options de config
- **docs/configuration.md** : r√©f√©rence compl√®te de `synapse.yaml`
- **docs/usage.md** : guide d'utilisation avanc√©e (ChatService, outils, events)
- **docs/views.md** : int√©gration Twig, layouts, personnalisation CSS
- **docs/changelog.md** : ce fichier

---

## Notes de migration

### ‚ö†Ô∏è Breaking Changes - Standardisation OpenAI

**Si vous avez cr√©√© un client LLM personnalis√©**, vous devez mettre √† jour ses signatures :

#### 1. Signatures des m√©thodes (LlmClientInterface)

**AVANT** :
```php
public function generateContent(
    string $systemInstruction,
    array $contents,
    array $tools = [],
    ?string $model = null,
    ?array $thinkingConfigOverride = null,
    array &$debugOut = [],
): array;
```

**APR√àS** :
```php
public function generateContent(
    array $contents,  // ‚Üê Contient le syst√®me en [0]
    array $tools = [],
    ?string $model = null,
    ?array $thinkingConfigOverride = null,
    array &$debugOut = [],
): array;
```

#### 2. Format des messages (OpenAI canonical)

**AVANT** : syst√®meInstruction s√©par√© + contents
```php
$systemInstruction = "You are helpful";
$contents = [
    ['role' => 'user', 'content' => '...'],
    ['role' => 'assistant', 'content' => '...'],
];
```

**APR√àS** : Tout dans contents, syst√®me en premier
```php
$contents = [
    ['role' => 'system', 'content' => 'You are helpful'],    // ‚Üê PREMIER
    ['role' => 'user', 'content' => '...'],
    ['role' => 'assistant', 'content' => '...'],
];
```

#### 3. Format du chunk retourn√©

**AVANT** : `blocked_category` (enum Gemini-sp√©cifique)
```php
return [
    'blocked' => true,
    'blocked_category' => 'HARM_CATEGORY_HATE_SPEECH',  // ‚Üê Constante Gemini
];
```

**APR√àS** : `blocked_reason` (string lisible, provider-agnostique)
```php
return [
    'blocked' => true,
    'blocked_reason' => 'discours haineux',  // ‚Üê String lisible
];
```

#### 4. Migration simple (exemple)

Si vous aviez un client personnalis√©, voici le pattern :

```php
class MyLLMClient implements LlmClientInterface {
    public function generateContent(
        array $contents,  // ‚Üê Nouvelle signature
        array $tools = [],
        ?string $model = null,
        ?array $thinkingConfigOverride = null,
        array &$debugOut = [],
    ): array {
        // 1. Extraire le syst√®me si pr√©sent
        $systemMessage = '';
        $contentsWithoutSystem = $contents;

        if (!empty($contents) && $contents[0]['role'] === 'system') {
            $systemMessage = $contents[0]['content'];
            $contentsWithoutSystem = array_slice($contents, 1);
        }

        // 2. Convertir au format de votre provider
        $providerMessages = $this->toProviderFormat($contentsWithoutSystem);

        // 3. Appeler votre API (avec ou sans syst√®me selon le provider)
        $response = $this->callApi($systemMessage, $providerMessages, ...);

        // 4. Normaliser la r√©ponse
        return $this->normalizeResponse($response);
    }
}
```

**Voir** : le [guide d'impl√©mentation](reference/implementation-guide.md) pour un guide complet.

### ‚úÖ Pas de changement requis pour
- Configuration (synapse.yaml, presets, safety_settings)
- Base de donn√©es (sch√©ma inchang√©)
- Interface admin (UI inchang√©e)
- Utilisation de ChatService (signatures publiques inchang√©es)
- Conversations existantes (compatibilit√© totale)

### Pour utiliser le chiffrement

### Pour utiliser le chiffrement
1. G√©n√©rer une cl√© : `php -r "echo bin2hex(sodium_crypto_secretbox_keygen());"`
2. Ajouter √† `.env.local` : `SYNAPSE_ENCRYPTION_KEY=base64:...`
3. Activer dans `synapse.yaml` :
   ```yaml
   encryption:
       enabled: true
       key: '%env(SYNAPSE_ENCRYPTION_KEY)%'
   ```
4. Les credentials existants seront chiffr√©s automatiquement lors de la prochaine sauvegarde

---

## Version future envisag√©e

- [ ] Support d'autres providers LLM (OpenAI, Anthropic Claude, etc.)
- [ ] T√©l√©chargement des logs de debug
- [ ] API publique pour les modules tiers
- [ ] Webhooks pour les √©v√©nements importants
- [ ] Syst√®me de plugins

---

## Liens utiles

- [Configuration](guides/configuration.md) ‚Äî Documentation compl√®te `synapse.yaml`
- [Guide rapide](getting-started/quickstart.md) ‚Äî Utilisation ChatService, outils, events
